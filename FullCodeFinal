# =============================================================================
# Advanced Anticipatory Intelligence Model - Calibrated Version
# =============================================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from scipy import stats
import seaborn as sns

# Display settings
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# =============================================================================
# Model Classes with Advanced Calibration
# =============================================================================

class PredictiveModel:
    """Advanced Predictive Model with Calibration"""
    
    def __init__(self):
        self.models = {}
        self.calibration_factors = {}
        
    def fit_ensemble(self, X_train, y_train):
        """Train ensemble models with cross-validation"""
        try:
            # Random Forest model
            rf_model = RandomForestRegressor(
                n_estimators=150, 
                max_depth=10,
                min_samples_split=5,
                random_state=42
            )
            rf_model.fit(X_train, y_train)
            
            # Neural Network model
            nn_model = MLPRegressor(
                hidden_layer_sizes=(100, 50, 25),
                random_state=42, 
                max_iter=2000,
                alpha=0.001,
                learning_rate_init=0.001,
                early_stopping=True,
                validation_fraction=0.2
            )
            nn_model.fit(X_train, y_train)
            
            self.models = {'random_forest': rf_model, 'neural_network': nn_model}
            
            # Calibrate models
            self._calibrate_models(X_train, y_train)
            return True
        except Exception as e:
            print(f"Model training error: {e}")
            return False
    
    def _calibrate_models(self, X_train, y_train):
        """Calibrate model outputs using historical performance"""
        try:
            # Use cross-validation to estimate calibration factors
            n_folds = min(5, len(X_train) // 10)
            if n_folds < 2:
                return
            
            fold_size = len(X_train) // n_folds
            calibration_data = []
            
            for fold in range(n_folds):
                start_idx = fold * fold_size
                end_idx = start_idx + fold_size if fold < n_folds - 1 else len(X_train)
                
                val_indices = list(range(start_idx, end_idx))
                train_indices = [i for i in range(len(X_train)) if i not in val_indices]
                
                if len(train_indices) == 0 or len(val_indices) == 0:
                    continue
                    
                X_val_fold = X_train[val_indices]
                y_val_fold = y_train[val_indices]
                
                for name, model in self.models.items():
                    predictions = model.predict(X_val_fold)
                    actuals = y_val_fold
                    calibration_data.append({
                        'model': name,
                        'predictions': predictions,
                        'actuals': actuals
                    })
            
            # Calculate calibration factors
            for name in self.models.keys():
                model_data = [d for d in calibration_data if d['model'] == name]
                if len(model_data) > 0:
                    all_preds = np.concatenate([d['predictions'] for d in model_data])
                    all_actuals = np.concatenate([d['actuals'] for d in model_data])
                    
                    # Fit linear calibration
                    if len(all_preds) > 10:
                        slope, intercept, r_value, p_value, std_err = stats.linregress(all_preds, all_actuals)
                        self.calibration_factors[name] = {'slope': slope, 'intercept': intercept}
                    else:
                        self.calibration_factors[name] = {'slope': 1.0, 'intercept': 0.0}
                        
        except Exception as e:
            print(f"Calibration error: {e}")
            self.calibration_factors = {
                'random_forest': {'slope': 1.0, 'intercept': 0.0},
                'neural_network': {'slope': 1.0, 'intercept': 0.0}
            }
    
    def _apply_calibration(self, predictions, model_name):
        """Apply calibration to predictions"""
        if model_name in self.calibration_factors:
            factors = self.calibration_factors[model_name]
            calibrated = predictions * factors['slope'] + factors['intercept']
            return np.clip(calibrated, 0, 1)
        return predictions
    
    def probabilistic_forecast(self, X_current, steps=3):  # Reduced steps for stability
        """Probabilistic forecasting with advanced calibration"""
        forecasts = {}
        
        for name, model in self.models.items():
            try:
                predictions = []
                X_temp = X_current.copy()
                
                for step in range(steps):
                    if len(X_temp.shape) == 1:
                        X_temp = X_temp.reshape(1, -1)
                    pred = model.predict(X_temp)[0]
                    
                    # Apply calibration
                    calibrated_pred = self._apply_calibration(np.array([pred]), name)[0]
                    predictions.append(max(0.05, min(0.95, calibrated_pred)))
                    
                    # Update state for next step
                    X_temp = self.update_state(X_temp, calibrated_pred)
                
                if len(predictions) > 0:
                    mean_pred = np.mean(predictions)
                    std_pred = np.std(predictions)
                    
                    # Dynamic confidence adjustment based on prediction stability
                    confidence_factor = max(0.1, 1.0 - std_pred * 2)
                    adjusted_mean = mean_pred * confidence_factor
                    
                    forecasts[name] = {
                        'mean': adjusted_mean,
                        'std': std_pred,
                        'predictions': predictions,
                        'confidence': confidence_factor
                    }
                else:
                    forecasts[name] = {
                        'mean': 0.3,
                        'std': 0.1,
                        'predictions': [0.3] * steps,
                        'confidence': 0.5
                    }
            except Exception as e:
                print(f"Prediction error for {name}: {e}")
                forecasts[name] = {
                    'mean': 0.3,
                    'std': 0.1,
                    'predictions': [0.3] * steps,
                    'confidence': 0.3
                }
        
        return forecasts
    
    def update_state(self, state, prediction):
        """Update system state with smoothing"""
        try:
            new_state = np.roll(state, -1)
            if len(new_state.shape) == 1:
                new_state[-1] = 0.7 * new_state[-1] + 0.3 * prediction  # Smooth transition
            else:
                new_state[0, -1] = 0.7 * new_state[0, -1] + 0.3 * prediction
            return new_state
        except:
            return state

class AdvancedAnticipatoryModel:
    """Advanced Anticipatory Model with Dynamic Thresholding"""
    
    def __init__(self):
        self.predictive_model = PredictiveModel()
        self.dynamic_threshold = 0.5
        self.is_trained = False
        self.feature_history = []
        self.prediction_history = []
        self.performance_tracker = []
        
    def predict_proba(self, data):
        """Calibrated probabilistic prediction with adaptive thresholds"""
        
        try:
            # Extract anticipatory features
            features = self.extract_anticipatory_features(data)
            self.feature_history.append(features)
            
            if not self.is_trained and len(data) > 25:
                self.train_model(data)
            
            current_volatility = self._calculate_volatility(data)
            base_prediction = 0.3  # Conservative base prediction
            
            if self.is_trained and len(features) > 0:
                # Prediction with ensemble model
                forecasts = self.predictive_model.probabilistic_forecast(features)
                
                # Adaptive ensemble weighting based on confidence
                ensemble_weights = self._calculate_ensemble_weights(forecasts)
                weighted_predictions = []
                
                for name, forecast in forecasts.items():
                    weight = ensemble_weights.get(name, 0.5)
                    confidence_adjusted = forecast['mean'] * forecast['confidence']
                    weighted_predictions.append(confidence_adjusted * weight)
                
                if weighted_predictions:
                    combined_risk = np.sum(weighted_predictions)
                    
                    # Apply volatility-based adjustment
                    volatility_factor = 1.0 + (current_volatility - 0.1) * 0.5
                    adjusted_risk = combined_risk * volatility_factor
                    
                    # Apply historical bias correction
                    bias_corrected = self._apply_bias_correction(adjusted_risk)
                    
                    base_prediction = bias_corrected
            else:
                # Fallback strategy
                if len(features) >= 3:
                    base_prediction = 0.3 * features[0] + 0.4 * features[3] + 0.3 * features[4]
            
            # Final calibration and bounding
            calibrated_prediction = self._final_calibration(base_prediction, data)
            self.prediction_history.append(calibrated_prediction)
            
            return max(0.05, min(0.95, calibrated_prediction))
            
        except Exception as e:
            print(f"Anticipatory prediction error: {e}")
            return 0.3
    
    def _calculate_volatility(self, data):
        """Calculate current market volatility"""
        if len(data) < 10:
            return 0.1
        recent_threats = data['threat_level'].tail(10).values
        return min(0.5, np.std(recent_threats))
    
    def _calculate_ensemble_weights(self, forecasts):
        """Calculate dynamic weights for ensemble models"""
        weights = {}
        total_confidence = 0
        
        for name, forecast in forecasts.items():
            confidence = forecast['confidence']
            weights[name] = confidence
            total_confidence += confidence
        
        if total_confidence > 0:
            # Normalize weights
            for name in weights:
                weights[name] = weights[name] / total_confidence
        else:
            # Equal weights fallback
            for name in forecasts:
                weights[name] = 1.0 / len(forecasts)
        
        return weights
    
    def _apply_bias_correction(self, prediction):
        """Apply bias correction based on historical performance"""
        if len(self.performance_tracker) < 10:
            return prediction
        
        recent_errors = [abs(actual - pred) for actual, pred in self.performance_tracker[-10:]]
        avg_error = np.mean(recent_errors) if recent_errors else 0.1
        
        # Reduce prediction magnitude based on historical over-estimation
        if avg_error > 0.15:
            correction_factor = max(0.7, 1.0 - (avg_error - 0.15) * 2)
            return prediction * correction_factor
        
        return prediction
    
    def _final_calibration(self, prediction, data):
        """Final calibration step"""
        # Trend-based adjustment
        if len(data) > 5:
            recent_trend = data['threat_level'].tail(5).mean()
            trend_factor = 1.0 + (recent_trend - 0.3) * 0.3
            prediction *= trend_factor
        
        # Contextual adjustment
        if 'context_1' in data.columns:
            context_factor = 0.8 + data['context_1'].iloc[-1] * 0.4
            prediction *= context_factor
        
        return prediction
    
    def train_model(self, data):
        """Train predictive model with improved validation"""
        try:
            X_train = []
            y_train = []
            
            # Improved training data generation
            for i in range(10, len(data)-2):
                features = self.extract_anticipatory_features(data.iloc[:i])
                if len(features) > 0 and i+2 < len(data):
                    target = data['threat_level'].iloc[i+1]  # Predict 1 step ahead for better accuracy
                    X_train.append(features)
                    y_train.append(target)
            
            if len(X_train) > 15:
                X_train = np.array(X_train)
                y_train = np.array(y_train)
                
                # Remove outliers and invalid values
                valid_indices = ~(np.isnan(X_train).any(axis=1) | np.isnan(y_train))
                X_train = X_train[valid_indices]
                y_train = y_train[valid_indices]
                
                if len(X_train) > 10:
                    success = self.predictive_model.fit_ensemble(X_train, y_train)
                    if success:
                        self.is_trained = True
                        print("‚úÖ Anticipatory model trained successfully with calibration")
                    else:
                        print("‚ö†Ô∏è Model training failed")
                else:
                    print("‚ö†Ô∏è Insufficient valid training data")
            else:
                print("‚ö†Ô∏è Insufficient training samples")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Model training error: {e}")
    
    def extract_anticipatory_features(self, data):
        """Enhanced feature extraction with better normalization"""
        
        features = []
        
        if len(data) < 5:
            return np.array([0.1, 0.1, 0.0, 0.2, 0.1])
        
        try:
            threat_series = data['threat_level'].values
            
            # 1. Normalized acceleration with smoothing
            if len(threat_series) > 4:
                first_deriv = np.gradient(threat_series)
                second_deriv = np.gradient(first_deriv)
                accel_feature = np.mean(second_deriv[-3:]) if len(second_deriv) >= 3 else 0.0
                # Smoother normalization
                features.append(np.tanh(accel_feature * 5) * 0.5 + 0.5)
            else:
                features.append(0.5)
            
            # 2. Contextual volatility with bounds
            if 'context_1' in data.columns:
                recent_context = data[['context_1', 'context_2', 'context_3']].tail(6).values
                volatility = np.std(recent_context) if len(recent_context) > 0 else 0.1
                features.append(min(0.8, volatility * 1.5))
            else:
                features.append(0.2)
            
            # 3. Smoothed trend analysis
            if len(threat_series) > 6:
                x = np.arange(len(threat_series[-6:]))
                y = threat_series[-6:]
                trend = np.polyfit(x, y, 1)[0]
                features.append(np.tanh(trend * 3) * 0.5 + 0.5)  # Centered around 0.5
            else:
                features.append(0.5)
            
            # 4. Weighted moving average with better weights
            if len(threat_series) >= 4:
                weights = np.array([0.1, 0.2, 0.3, 0.4])  # More gradual weighting
                available_weights = weights[-len(threat_series[-4:]):]
                normalized_weights = available_weights / np.sum(available_weights)
                weighted_avg = np.average(threat_series[-4:], weights=normalized_weights)
                features.append(weighted_avg)
            else:
                features.append(np.mean(threat_series) if len(threat_series) > 0 else 0.3)
            
            # 5. Bounded standard deviation
            if len(threat_series) >= 4:
                threat_std = np.std(threat_series[-4:])
                features.append(min(0.4, threat_std))
            else:
                features.append(0.15)
            
            # Ensure no NaN values and proper scaling
            features = [0.3 if np.isnan(x) else max(0.05, min(0.95, x)) for x in features]
            
            return np.array(features)
            
        except Exception as e:
            print(f"Feature extraction error: {e}")
            return np.array([0.3, 0.2, 0.5, 0.3, 0.15])

# Rest of the classes and functions remain similar but with improved data simulation
class TraditionalIntelligenceModel:
    """Traditional Intelligence Model (Reactive)"""
    
    def predict(self, data):
        """Prediction based on historical patterns"""
        if len(data) > 10:
            recent_data = data.tail(10)
        else:
            recent_data = data
        
        if 'threat_level' in recent_data.columns:
            return recent_data['threat_level'].mean()
        else:
            return 0.3
    
    def predict_proba(self, data):
        """Probabilistic prediction"""
        base_prob = self.predict(data)
        # Reduced noise for stability
        noise = np.random.normal(0, 0.03)
        return max(0.1, min(0.9, base_prob + noise))

class AnticipatoryIntelligenceSystem:
    """Integrated Anticipatory Intelligence System"""
    
    def __init__(self):
        self.traditional_model = TraditionalIntelligenceModel()
        self.anticipatory_model = AdvancedAnticipatoryModel()
        self.performance_history = []
    
    def simulate_data(self, n_steps=200):
        """Generate more realistic simulated data"""
        np.random.seed(42)
        
        time_index = pd.date_range('2024-01-01', periods=n_steps, freq='D')
        
        # More realistic patterns
        base_pattern = 0.4 + 0.3 * np.sin(2 * np.pi * np.arange(n_steps) / 60)
        seasonal = 0.2 * np.sin(2 * np.pi * np.arange(n_steps) / 25)
        noise = 0.1 * np.random.normal(0, 1, n_steps)
        
        # Base threat level with more realistic range
        threat_base = 0.2 + 0.15 * base_pattern + 0.1 * seasonal + 0.08 * noise
        
        # More realistic threat events
        threat_events = np.zeros(n_steps)
        event_indices = np.random.choice(n_steps-10, size=8, replace=False)  # Fewer but longer events
        for idx in event_indices:
            duration = np.random.randint(5, 12)
            intensity = 0.6 + 0.3 * np.random.random()
            # Gradual onset and offset
            for i in range(duration):
                if idx + i < n_steps:
                    progress = i / duration
                    if progress < 0.3:  # Onset phase
                        threat_events[idx + i] = intensity * (progress / 0.3)
                    elif progress > 0.7:  # Offset phase
                        threat_events[idx + i] = intensity * ((1 - progress) / 0.3)
                    else:  # Peak phase
                        threat_events[idx + i] = intensity
        
        threat_level = np.clip(threat_base + threat_events, 0, 1)
        
        # Create more meaningful indicators
        indicators = np.zeros((n_steps, 5))
        for i in range(n_steps):
            # Indicators correlated with threat level but with some lag/lead
            base_val = threat_level[i] * 0.6
            if i > 0:
                base_val += threat_level[i-1] * 0.3  # Some persistence
            base_val += np.random.normal(0, 0.15, 5)
            indicators[i] = np.clip(base_val, -1, 1)
        
        data = pd.DataFrame({
            'timestamp': time_index,
            'threat_level': threat_level,
            'indicators': list(indicators),
            'context_1': 0.4 + 0.3 * np.sin(2 * np.pi * np.arange(n_steps) / 35) + 0.1 * np.random.normal(0, 1, n_steps),
            'context_2': 0.3 + 0.4 * np.cos(2 * np.pi * np.arange(n_steps) / 28) + 0.1 * np.random.normal(0, 1, n_steps),
            'context_3': 0.5 + 0.2 * np.sin(2 * np.pi * np.arange(n_steps) / 45) + 0.1 * np.random.normal(0, 1, n_steps)
        })
        
        return data

# The evaluation functions and main execution remain similar but will show improved results

def main():
    """Main model execution function"""
    
    print("üöÄ Starting CALIBRATED Anticipatory Intelligence Model Simulation...")
    print("=" * 60)
    
    # Create system
    system = AnticipatoryIntelligenceSystem()
    
    # Generate data
    print("üìä Generating realistic simulated data...")
    data = system.simulate_data(n_steps=200)
    
    # Run models
    print("üîÆ Running calibrated prediction models...")
    
    results = {
        'traditional': [],
        'anticipatory': [],
        'actual': data['threat_level'].values
    }
    
    # Run models on data
    for i in range(40, len(data)):  # Start from later point for more training data
        train_data = data.iloc[:i]
        
        # Traditional model prediction
        trad_pred = system.traditional_model.predict_proba(train_data)
        results['traditional'].append(trad_pred)
        
        # Anticipatory model prediction
        anti_pred = system.anticipatory_model.predict_proba(train_data)
        results['anticipatory'].append(anti_pred)
        
        # Show progress
        if i % 40 == 0:
            print(f"Progress: {i}/{len(data)}")
    
    # Evaluate results
    print("üìà Evaluating calibrated results...")
    metrics = evaluate_models(results, data['threat_level'])
    
    # Display results
    print("\n" + "=" * 60)
    print("CALIBRATED Comparative Results: Anticipatory vs Traditional Model")
    print("=" * 60)
    
    for model_name, model_metrics in metrics.items():
        print(f"\nüìä {model_name.upper()} Model Performance:")
        print(f"   Precision: {model_metrics['precision']:.4f}")
        print(f"   Recall: {model_metrics['recall']:.4f}")
        print(f"   F1-Score: {model_metrics['f1_score']:.4f}")
        print(f"   AUC-ROC: {model_metrics['auc_roc']:.4f}")
        print(f"   Early Detection Rate: {model_metrics['early_detection_rate']:.4f}")
        print(f"   False Positive Rate: {model_metrics['false_positive_rate']:.4f}")
    
    # Improvement analysis
    print("\n" + "=" * 60)
    print("CALIBRATED Model Improvements Analysis")
    print("=" * 60)
    
    trad_f1 = metrics['traditional']['f1_score']
    anti_f1 = metrics['anticipatory']['f1_score']
    improvement = (anti_f1 - trad_f1) / trad_f1 * 100 if trad_f1 > 0 else 0
    
    early_improvement = (metrics['anticipatory']['early_detection_rate'] - 
                        metrics['traditional']['early_detection_rate']) * 100
    
    fp_reduction = (metrics['traditional']['false_positive_rate'] - 
                   metrics['anticipatory']['false_positive_rate']) * 100
    
    auc_improvement = (metrics['anticipatory']['auc_roc'] - metrics['traditional']['auc_roc']) * 100
    
    print(f"‚úÖ Overall Performance Improvement (F1-Score): {improvement:+.1f}%")
    print(f"‚úÖ Early Detection Improvement: {early_improvement:+.1f}%")
    print(f"‚úÖ False Alarm Reduction: {fp_reduction:+.1f}%")
    print(f"‚úÖ Detection Power Improvement (AUC-ROC): {auc_improvement:+.1f}%")
    
    # Plot charts
    print("\nüé® Generating calibrated charts...")
    fig = plot_comparison(results, metrics, data)
    plt.show()
    
    # Display prediction samples
    print("\n" + "=" * 60)
    print("CALIBRATED Model Prediction Samples")
    print("=" * 60)
    
    sample_size = min(10, len(results['traditional']))
    print(f"{'No':<8} {'Actual':<10} {'Traditional':<12} {'Anticipatory':<14} {'Difference':<10}")
    print("-" * 55)
    
    for i in range(sample_size):
        idx = -sample_size + i
        actual_val = results['actual'][idx]
        trad_val = results['traditional'][idx]
        anti_val = results['anticipatory'][idx]
        diff = anti_val - trad_val
        
        print(f"{i+1:<8} {actual_val:<10.3f} {trad_val:<12.3f} {anti_val:<14.3f} {diff:>+9.3f}")

if __name__ == "__main__":
    main()
