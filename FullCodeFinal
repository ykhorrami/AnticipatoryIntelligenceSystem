# =============================================================================
# Advanced Anticipatory Intelligence Model - Integrated Code (Fixed - English Version)
# =============================================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve
import seaborn as sns

# Display settings
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# =============================================================================
# Model Classes
# =============================================================================

class PredictiveModel:
    """Advanced Predictive Model"""
    
    def __init__(self):
        self.models = {}
        
    def fit_ensemble(self, X_train, y_train):
        """Train ensemble models for prediction"""
        try:
            # Random Forest model
            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
            rf_model.fit(X_train, y_train)
            
            # Neural Network model
            nn_model = MLPRegressor(hidden_layer_sizes=(50, 25), random_state=42, max_iter=1000, 
                                  alpha=0.001, learning_rate_init=0.001)
            nn_model.fit(X_train, y_train)
            
            self.models = {'random_forest': rf_model, 'neural_network': nn_model}
            return True
        except Exception as e:
            print(f"Model training error: {e}")
            return False
    
    def probabilistic_forecast(self, X_current, steps=5):
        """Probabilistic forecasting with confidence intervals"""
        forecasts = {}
        
        for name, model in self.models.items():
            try:
                predictions = []
                X_temp = X_current.copy()
                
                for step in range(steps):
                    if len(X_temp.shape) == 1:
                        X_temp = X_temp.reshape(1, -1)
                    pred = model.predict(X_temp)[0]
                    predictions.append(max(0, min(1, pred)))  # Limit to [0,1] range
                    # Update state for next step
                    X_temp = self.update_state(X_temp, pred)
                
                if len(predictions) > 0:
                    forecasts[name] = {
                        'mean': np.mean(predictions),
                        'std': np.std(predictions),
                        'predictions': predictions
                    }
                else:
                    forecasts[name] = {
                        'mean': 0.3,
                        'std': 0.1,
                        'predictions': [0.3] * steps
                    }
            except Exception as e:
                print(f"Prediction error for {name}: {e}")
                forecasts[name] = {
                    'mean': 0.3,
                    'std': 0.1,
                    'predictions': [0.3] * steps
                }
        
        return forecasts
    
    def update_state(self, state, prediction):
        """Update system state"""
        try:
            new_state = np.roll(state, -1)
            if len(new_state.shape) == 1:
                new_state[-1] = prediction
            else:
                new_state[0, -1] = prediction
            return new_state
        except:
            return state

class TraditionalIntelligenceModel:
    """Traditional Intelligence Model (Reactive)"""
    
    def predict(self, data):
        """Prediction based on historical patterns"""
        if len(data) > 10:
            recent_data = data.tail(10)
        else:
            recent_data = data
        
        if 'threat_level' in recent_data.columns:
            return recent_data['threat_level'].mean()
        else:
            return 0.3
    
    def predict_proba(self, data):
        """Probabilistic prediction"""
        base_prob = self.predict(data)
        # Add small noise to simulate uncertainty
        noise = np.random.normal(0, 0.05)  # Reduced noise for more stability
        return max(0.1, min(0.9, base_prob + noise))

class AdvancedAnticipatoryModel:
    """Advanced Anticipatory Model"""
    
    def __init__(self):
        self.predictive_model = PredictiveModel()
        self.risk_threshold = 0.6
        self.is_trained = False
        self.feature_history = []
        
    def predict_proba(self, data):
        """Probabilistic prediction considering leading indicators"""
        
        try:
            # Extract anticipatory features
            features = self.extract_anticipatory_features(data)
            self.feature_history.append(features)
            
            if not self.is_trained and len(data) > 20:  # Reduced minimum data for training
                self.train_model(data)
            
            if self.is_trained and len(features) > 0:
                # Prediction with ensemble model
                forecasts = self.predictive_model.probabilistic_forecast(features)
                
                # Combine predictions with weighting
                if 'random_forest' in forecasts and 'neural_network' in forecasts:
                    rf_pred = forecasts['random_forest']['mean']
                    nn_pred = forecasts['neural_network']['mean']
                    
                    # Weight predictions based on historical accuracy
                    combined_risk = 0.6 * rf_pred + 0.4 * nn_pred
                else:
                    combined_risk = np.mean(features[:3]) if len(features) >= 3 else 0.3
            else:
                # Fallback to improved model
                if len(features) >= 3:
                    combined_risk = 0.4 * features[0] + 0.3 * features[3] + 0.3 * features[4]
                else:
                    combined_risk = 0.3
            
            # Apply filter for output smoothing
            combined_risk = max(0.1, min(0.9, combined_risk))
            return combined_risk
            
        except Exception as e:
            print(f"Anticipatory prediction error: {e}")
            return 0.3
    
    def train_model(self, data):
        """Train predictive model"""
        try:
            X_train = []
            y_train = []
            
            # Use more data for training
            for i in range(5, len(data)-3):  # Reduced prediction horizon from 5 to 3
                features = self.extract_anticipatory_features(data.iloc[:i])
                if len(features) > 0 and i+3 < len(data):
                    target = data['threat_level'].iloc[i+2]  # Predict 2 steps ahead
                    X_train.append(features)
                    y_train.append(target)
            
            if len(X_train) > 10:  # Minimum samples for training
                X_train = np.array(X_train)
                y_train = np.array(y_train)
                
                # Remove invalid values
                valid_indices = ~np.isnan(X_train).any(axis=1) & ~np.isnan(y_train)
                X_train = X_train[valid_indices]
                y_train = y_train[valid_indices]
                
                if len(X_train) > 5:
                    success = self.predictive_model.fit_ensemble(X_train, y_train)
                    if success:
                        self.is_trained = True
                        print("‚úÖ Anticipatory model trained successfully")
                    else:
                        print("‚ö†Ô∏è Model training failed")
                else:
                    print("‚ö†Ô∏è Insufficient training data")
            else:
                print("‚ö†Ô∏è Insufficient training samples")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Model training error: {e}")
    
    def extract_anticipatory_features(self, data):
        """Extract leading indicators from data"""
        
        features = []
        
        if len(data) < 3:
            # Return default features for limited data
            return np.array([0.2, 0.2, 0.0, 0.3, 0.1])
        
        try:
            # 1. Rate of change acceleration (weak signal)
            threat_series = data['threat_level'].values
            if len(threat_series) > 3:
                first_deriv = np.gradient(threat_series)
                second_deriv = np.gradient(first_deriv)
                # Normalization
                accel_feature = np.mean(second_deriv[-3:]) if len(second_deriv) >= 3 else 0.0
                features.append(np.tanh(accel_feature * 10))  # Tanh for range limiting
            else:
                features.append(0.0)
            
            # 2. Abnormal volatility
            if 'context_1' in data.columns:
                recent_context = data[['context_1', 'context_2', 'context_3']].tail(5).values
                volatility = np.std(recent_context) if len(recent_context) > 0 else 0.1
                features.append(min(1.0, volatility * 2))
            else:
                features.append(0.1)
            
            # 3. Trend changes
            if len(threat_series) > 4:
                x = np.arange(len(threat_series[-4:]))
                y = threat_series[-4:]
                trend = np.polyfit(x, y, 1)[0]  # Slope
                features.append(np.tanh(trend * 5))  # Normalization
            else:
                features.append(0.0)
            
            # 4. Weighted moving average (emphasis on recent data)
            if len(threat_series) >= 3:
                weights = np.array([0.1, 0.3, 0.6])  # More weight to newer data
                weighted_avg = np.average(threat_series[-3:], weights=weights[-len(threat_series[-3:]):])
                features.append(weighted_avg)
            else:
                features.append(np.mean(threat_series) if len(threat_series) > 0 else 0.3)
            
            # 5. Normalized standard deviation
            if len(threat_series) >= 3:
                threat_std = np.std(threat_series[-3:])
                features.append(min(0.5, threat_std))  # Limit standard deviation
            else:
                features.append(0.1)
            
            # Ensure no NaN values
            features = [0.1 if np.isnan(x) else x for x in features]
            
            return np.array(features)
            
        except Exception as e:
            print(f"Feature extraction error: {e}")
            return np.array([0.2, 0.2, 0.0, 0.3, 0.1])

class AnticipatoryIntelligenceSystem:
    """Integrated Anticipatory Intelligence System"""
    
    def __init__(self):
        self.traditional_model = TraditionalIntelligenceModel()
        self.anticipatory_model = AdvancedAnticipatoryModel()
        self.performance_history = []
    
    def simulate_data(self, n_steps=200):
        """Generate simulated data"""
        np.random.seed(42)
        
        time_index = pd.date_range('2024-01-01', periods=n_steps, freq='D')
        
        # Create complex patterns in data
        base_pattern = np.sin(2 * np.pi * np.arange(n_steps) / 50)
        seasonal = 0.3 * np.sin(2 * np.pi * np.arange(n_steps) / 20)
        noise = 0.15 * np.random.normal(0, 1, n_steps)  # Reduced noise
        
        # Base threat level with complex patterns
        threat_base = 0.3 + 0.25 * base_pattern + 0.15 * seasonal + 0.1 * noise
        
        # Add random threat events
        threat_events = np.zeros(n_steps)
        event_indices = np.random.choice(n_steps-8, size=12, replace=False)  # Reduced number of events
        for idx in event_indices:
            duration = np.random.randint(3, 7)
            intensity = 0.7 + 0.2 * np.random.random()
            threat_events[idx:idx+duration] = intensity
        
        threat_level = np.clip(threat_base + threat_events, 0, 1)
        
        # Create threat-dependent indicators
        indicators = np.zeros((n_steps, 5))
        for i in range(n_steps):
            base_val = threat_level[i] * 0.7 + np.random.normal(0, 0.2, 5)
            indicators[i] = np.clip(base_val, -1, 1)
        
        data = pd.DataFrame({
            'timestamp': time_index,
            'threat_level': threat_level,
            'indicators': list(indicators),
            'context_1': 0.3 + 0.4 * np.sin(2 * np.pi * np.arange(n_steps) / 30) + 0.1 * np.random.normal(0, 1, n_steps),
            'context_2': 0.4 + 0.3 * np.cos(2 * np.pi * np.arange(n_steps) / 25) + 0.1 * np.random.normal(0, 1, n_steps),
            'context_3': 0.5 + 0.2 * np.sin(2 * np.pi * np.arange(n_steps) / 40) + 0.1 * np.random.normal(0, 1, n_steps)
        })
        
        return data

# =============================================================================
# Evaluation Functions
# =============================================================================

def calculate_early_detection(actual, predicted, window=5):
    """Calculate early detection rate"""
    early_detections = 0
    total_threats = 0
    
    actual_array = actual if isinstance(actual, np.ndarray) else actual.values
    
    for i in range(len(predicted)):
        if i < len(actual_array) and actual_array[i] > 0.7:  # Real threat
            total_threats += 1
            # Check if warning was given in previous window
            for j in range(max(0, i-window), i):
                if j < len(predicted) and predicted[j] > 0.6:
                    early_detections += 1
                    break
    
    return early_detections / total_threats if total_threats > 0 else 0

def calculate_false_positive(actual, predicted):
    """Calculate false positive rate"""
    actual_binary = (actual > 0.7).astype(int)
    predicted_binary = (np.array(predicted) > 0.6).astype(int)
    
    fp = np.sum((predicted_binary == 1) & (actual_binary == 0))
    total_negatives = np.sum(actual_binary == 0)
    
    return fp / total_negatives if total_negatives > 0 else 0

def evaluate_models(results, actual):
    """Comprehensive model performance evaluation"""
    
    metrics = {}
    actual_array = actual.values if isinstance(actual, pd.Series) else actual
    
    for model_name, predictions in results.items():
        if model_name == 'actual':
            continue
            
        pred_array = np.array(predictions)
        actual_subset = actual_array[-len(pred_array):]
        
        pred_binary = (pred_array > 0.5).astype(int)
        actual_binary = (actual_subset > 0.5).astype(int)
        
        if len(np.unique(actual_binary)) > 1 and len(np.unique(pred_binary)) > 1:
            # Calculate metrics
            precision = precision_score(actual_binary, pred_binary, zero_division=0)
            recall = recall_score(actual_binary, pred_binary, zero_division=0)
            f1 = f1_score(actual_binary, pred_binary, zero_division=0)
            auc_roc = roc_auc_score(actual_binary, pred_array)
        else:
            precision = recall = f1 = auc_roc = 0.5
        
        metrics[model_name] = {
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'auc_roc': auc_roc,
            'early_detection_rate': calculate_early_detection(actual_subset, pred_array),
            'false_positive_rate': calculate_false_positive(actual_subset, pred_array)
        }
    
    return metrics

def plot_comparison(results, metrics, data):
    """Plot comparative charts"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # Chart 1: Prediction comparison over time
    time_points = range(len(results['traditional']))
    actual_values = data['threat_level'].values[-len(results['traditional']):]
    
    ax1.plot(time_points, results['traditional'], 'r-', label='Traditional Model', alpha=0.7, linewidth=2)
    ax1.plot(time_points, results['anticipatory'], 'b-', label='Anticipatory Model', alpha=0.7, linewidth=2)
    ax1.plot(time_points, actual_values, 'g--', label='Ground Truth', alpha=0.7, linewidth=1)
    ax1.set_title('Threat Prediction Comparison Over Time', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Time')
    ax1.set_ylabel('Threat Level')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Chart 2: Performance metrics
    model_names = list(metrics.keys())
    performance_metrics = ['precision', 'recall', 'f1_score']
    
    x_pos = np.arange(len(model_names))
    width = 0.25
    
    for i, metric in enumerate(performance_metrics):
        values = [metrics[model][metric] for model in model_names]
        ax2.bar(x_pos + i*width, values, width, label=metric, alpha=0.8)
    
    ax2.set_title('Performance Metrics Comparison', fontsize=14, fontweight='bold')
    ax2.set_xticks(x_pos + width)
    ax2.set_xticklabels(model_names)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Chart 3: Early detection vs False alarms
    early_detection = [metrics[model]['early_detection_rate'] for model in model_names]
    false_positive = [metrics[model]['false_positive_rate'] for model in model_names]
    
    x = np.arange(len(model_names))
    ax3.bar(x - 0.2, early_detection, 0.4, label='Early Detection', alpha=0.8)
    ax3.bar(x + 0.2, false_positive, 0.4, label='False Positive', alpha=0.8)
    ax3.set_title('Early Detection vs False Alarms', fontsize=14, fontweight='bold')
    ax3.set_xticks(x)
    ax3.set_xticklabels(model_names)
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Chart 4: ROC curve
    for model_name in model_names:
        if model_name in results and len(results[model_name]) > 0:
            actual_binary = (data['threat_level'].values[-len(results[model_name]):] > 0.5).astype(int)
            if len(np.unique(actual_binary)) > 1:
                fpr, tpr, _ = roc_curve(actual_binary, results[model_name])
                ax4.plot(fpr, tpr, label=f'{model_name} (AUC = {metrics[model_name]["auc_roc"]:.3f})', linewidth=2)
    
    ax4.plot([0, 1], [0, 1], 'k--', alpha=0.5)
    ax4.set_title('ROC Curve', fontsize=14, fontweight='bold')
    ax4.set_xlabel('False Positive Rate')
    ax4.set_ylabel('True Positive Rate')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

# =============================================================================
# Main Execution
# =============================================================================

def main():
    """Main model execution function"""
    
    print("üöÄ Starting Anticipatory Intelligence Model Simulation...")
    print("=" * 60)
    
    # Create system
    system = AnticipatoryIntelligenceSystem()
    
    # Generate data
    print("üìä Generating simulated data...")
    data = system.simulate_data(n_steps=200)
    
    # Run models
    print("üîÆ Running prediction models...")
    
    results = {
        'traditional': [],
        'anticipatory': [],
        'actual': data['threat_level'].values
    }
    
    # Run models on data
    for i in range(30, len(data)):  # Start from earlier point
        train_data = data.iloc[:i]
        
        # Traditional model prediction
        trad_pred = system.traditional_model.predict_proba(train_data)
        results['traditional'].append(trad_pred)
        
        # Anticipatory model prediction
        anti_pred = system.anticipatory_model.predict_proba(train_data)
        results['anticipatory'].append(anti_pred)
        
        # Show progress
        if i % 40 == 0:
            print(f"Progress: {i}/{len(data)}")
    
    # Evaluate results
    print("üìà Evaluating results...")
    metrics = evaluate_models(results, data['threat_level'])
    
    # Display results
    print("\n" + "=" * 60)
    print("Comparative Results: Anticipatory vs Traditional Model")
    print("=" * 60)
    
    for model_name, model_metrics in metrics.items():
        print(f"\nüìä {model_name.upper()} Model Performance:")
        print(f"   Precision: {model_metrics['precision']:.4f}")
        print(f"   Recall: {model_metrics['recall']:.4f}")
        print(f"   F1-Score: {model_metrics['f1_score']:.4f}")
        print(f"   AUC-ROC: {model_metrics['auc_roc']:.4f}")
        print(f"   Early Detection Rate: {model_metrics['early_detection_rate']:.4f}")
        print(f"   False Positive Rate: {model_metrics['false_positive_rate']:.4f}")
    
    # Improvement analysis
    print("\n" + "=" * 60)
    print("Anticipatory Model Improvements Analysis")
    print("=" * 60)
    
    trad_f1 = metrics['traditional']['f1_score']
    anti_f1 = metrics['anticipatory']['f1_score']
    improvement = (anti_f1 - trad_f1) / trad_f1 * 100 if trad_f1 > 0 else 0
    
    early_improvement = (metrics['anticipatory']['early_detection_rate'] - 
                        metrics['traditional']['early_detection_rate']) * 100
    
    fp_reduction = (metrics['traditional']['false_positive_rate'] - 
                   metrics['anticipatory']['false_positive_rate']) * 100
    
    print(f"‚úÖ Overall Performance Improvement (F1-Score): {improvement:+.1f}%")
    print(f"‚úÖ Early Detection Improvement: {early_improvement:+.1f}%")
    print(f"‚úÖ False Alarm Reduction: {fp_reduction:+.1f}%")
    print(f"‚úÖ Detection Power Improvement (AUC-ROC): {(metrics['anticipatory']['auc_roc'] - metrics['traditional']['auc_roc'])*100:+.1f}%")
    
    # Plot charts
    print("\nüé® Generating charts...")
    fig = plot_comparison(results, metrics, data)
    plt.show()
    
    # Display prediction samples
    print("\n" + "=" * 60)
    print("Model Prediction Samples")
    print("=" * 60)
    
    sample_size = min(10, len(results['traditional']))
    print(f"{'No':<8} {'Actual':<10} {'Traditional':<12} {'Anticipatory':<14} {'Difference':<10}")
    print("-" * 55)
    
    for i in range(sample_size):
        idx = -sample_size + i
        actual_val = results['actual'][idx]
        trad_val = results['traditional'][idx]
        anti_val = results['anticipatory'][idx]
        diff = anti_val - trad_val
        
        print(f"{i+1:<8} {actual_val:<10.3f} {trad_val:<12.3f} {anti_val:<14.3f} {diff:>+9.3f}")

if __name__ == "__main__":
    main()
